{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code To train and test our models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import pydicom as dicom\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'C:\\\\Users\\\\kmorales\\\\Desktop\\\\2DO PhD\\\\Strasbourg\\\\Hugo_seg\\\\ora_180919\\\\Layers\\\\train\\\\mask\\\\CV40642_SFA002_Dist_1257.A.4.1.5.grayscale_calcificacion.png'\n",
    "# img = read_image(path, mask = True )\n",
    "# print(np.unique(img))\n",
    "# plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # if more_classes:\n",
    "    #     label_more_classses = (mask == mask_class-2)*1  \n",
    "    #     contours_more_classses , _ = cv2.findContours(label.astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #     idxs_more_classses =  list(np.where(np.array([cv2.contourArea(x) for x in contours_more_classses])>Area_more_classses))[0]\n",
    "    #     pix_more_classses  = np.sum(label)\n",
    "    #     if pix_more_classses >100 and len(idxs_more_classses)>0:   \n",
    "    #         for idx in idxs_more_classses:\n",
    "    #             x,y,w,h = cv2.boundingRect(contours_more_classses[int(idx)])\n",
    "    #             box_info.append([x,y,w,h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import product\n",
    "# d = 64\n",
    "# label_more_classses = read_image(path, mask = True )\n",
    "\n",
    "# contours_more_classses , _ = cv2.findContours(label_more_classses.astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# areas = [cv2.contourArea(x) for x in contours_more_classses]\n",
    "# idxs_big =  int(list(np.where(areas==np.max(areas)))[0])\n",
    "\n",
    "# x,y,w,h = cv2.boundingRect(contours_more_classses[idxs_big])\n",
    "# img   = label_more_classses[y:y+h,x:x+w]\n",
    "# img_cal = label[y:y+h,x:x+w]\n",
    "# print(x,y,w,h)\n",
    "# w, h = img.shape\n",
    "# if w >=d and h >=d:\n",
    "#     grid = product(range(0, h-h%d, d), range(0, w-w%d, d))\n",
    "#     if np.sum(img_cal[y:y+d,x:x+d])< d**2//10\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# # idxs_more_classses =  list(np.where(np.array([cv2.contourArea(x) for x in contours_more_classses])>Area_more_classses))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import product\n",
    "\n",
    "# w, h = img.shape\n",
    "# d = 128\n",
    "\n",
    "# grid = product(range(0, h-h%d, d), range(0, w-w%d, d))\n",
    "# for x, y in grid:\n",
    "#     img_new = img[y:y+d,x:x+d]\n",
    "#     value = np.sum(img[y:y+d,x:x+d])\n",
    "#     if value < d**2//10:\n",
    "        \n",
    "#     plt.imshow(img_new)\n",
    "#     plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# name = 'CV40646_SFA006_0489'\n",
    "# path = r'C:\\Users\\kmorales\\Desktop\\2DO PhD\\Strasbourg\\Hugo_seg\\ora_180919\\Layers'\n",
    "\n",
    "# files = [os.path.join(path, 'train', 'mask', f) for f in os.listdir(os.path.join(path, 'train', 'mask'))] + \\\n",
    "#     [os.path.join(path, 'test', 'mask', f) for f in os.listdir(os.path.join(path, 'test', 'mask'))]\n",
    "# files_calcs = [f for f in files if 'calc' in f and '.png' in f]\n",
    "\n",
    "# cal_nodular = ['CV40646_SFA006_0489', 'CV40642_SFA002_Dist_1257']\n",
    "# cal_sheet = ['CV40642_SFA002_Prox_0426', 'CV40642_SFA002_Prox_0811', 'SFA015Mid0247']\n",
    "\n",
    "# for name in cal_nodular + cal_sheet:\n",
    "#     imagePath =  [f for f in files_calcs if name in f]\n",
    "#     print(imagePath)\n",
    "#     calc = read_image(imagePath[0], mask = True )\n",
    "#     nodular =  read_image(imagePath[1], mask = True )\n",
    "#     image = calc - nodular\n",
    "#     image = (image == 1)*1\n",
    "#     print(np.sum(image))\n",
    "#     plt.imshow(image)  \n",
    "#     plt.show()\n",
    "\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from itertools import product\n",
    "\n",
    "def str_after_before(idx):\n",
    "    '''\n",
    "    A function to combine the indexation on t+1 and t-1 wrt the actual image (t)\n",
    "    '''\n",
    "    if idx >=0 and idx <100:\n",
    "        idx_str = str(0)+str(0)+str(idx)\n",
    "    if idx >=100 and idx <1000:\n",
    "        idx_str = str(0)+str(idx)\n",
    "    if idx >=1000:\n",
    "        idx_str = str(idx)\n",
    "    return idx_str\n",
    "    \n",
    "\n",
    "def create_path_after_before(path_mct , names, names_files):\n",
    "    '''\n",
    "    YA NO.... Pilas aqui cuando vaya a utilizarlo con las demas carpetas porque hago un zip entre los directorios y los names que tengo disponibles\n",
    "    Creation of path for images at time t-1 and t+1 wrt to the actual image t (image with its true mask)\n",
    "    '''\n",
    "    path_mct_files = []\n",
    "    for path_, name in zip(path_mct, names_files):\n",
    "        path_mct_files += [os.path.join(path_, f+'.dcm')   for f in names if name in f and f+'.dcm' in os.listdir(path_)]\n",
    "    return path_mct_files\n",
    "\n",
    "def read_image_dicom(imagePath):\n",
    "    ''' \n",
    "    Lecture of DICOM images, it includes  normalization and transformation to gray scale (2 dimensions) \n",
    "    '''\n",
    "    image = dicom.dcmread(imagePath).pixel_array\n",
    "    # image =  cv2.normalize(image.astype(np.float32),  None, 0, 255, cv2.NORM_MINMAX)\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)/255\n",
    "    return image\n",
    "\n",
    "\n",
    "def read_image(imagePath, mask = True ):\n",
    "    if mask and imagePath != '':\n",
    "        image = cv2.imread(imagePath, 0)\n",
    "        image = cv2.normalize(image.astype(np.int16),  None, 0, 255, cv2.NORM_MINMAX) \n",
    "        image = np.where(image != 0, 1, 0)\n",
    "        # if 'soft_tissue' in imagePath:\n",
    "        #     print(imagePath.split('\\\\')[-1])\n",
    "        #     plt.imshow(image)\n",
    "        #     plt.show()\n",
    "        #(thresh, image) = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "    if mask == False and imagePath != '':\n",
    "        image = cv2.imread(imagePath)    \n",
    "        image = cv2.normalize(image.astype(np.int16),  None, 0, 255, cv2.NORM_MINMAX)\n",
    "        image = cv2.cvtColor( np.float32(image[:,:,1]),cv2.COLOR_GRAY2RGB)/255\n",
    "    if  mask and imagePath == '':\n",
    "        image =  99\n",
    "    return image\n",
    "\n",
    "def create_img_mask(mask_Path, mask = True):\n",
    "    list_images = []\n",
    "    for imagePath in mask_Path:\n",
    "        list_images.append(read_image(imagePath,  mask))\n",
    "    return list_images\n",
    "\n",
    "\n",
    "def create_binary_mask(mask_Path, name):\n",
    "    list_images = create_img_mask(mask_Path)\n",
    "    #print(len(list_images))\n",
    "    #list_images.reverse()\n",
    "    shapes = [image.shape for image in list_images if not isinstance(image, int)]\n",
    "    n, m = shapes[0]\n",
    "    mask_img = np.zeros((n,m),np.int64) \n",
    "    for i, image in enumerate(list_images):\n",
    "        if not isinstance(image, int):\n",
    "\n",
    "            mask_img[ image == 1 ]  = (i+1)\n",
    "    \n",
    "    imagePath = ['C:\\\\Users\\\\kmorales\\\\Desktop\\\\2DO PhD\\\\Strasbourg\\\\Hugo_seg\\\\ora_180919\\\\Layers\\\\train\\\\mask\\\\CV40642_SFA002_Dist_1257.A.4.1.5.grayscale_calcificacion.png', \\\n",
    "        'C:\\\\Users\\\\kmorales\\\\Desktop\\\\2DO PhD\\\\Strasbourg\\\\Hugo_seg\\\\ora_180919\\\\Layers\\\\train\\\\mask\\\\CV40642_SFA002_Dist_1257.A.4.1.5.grayscale_calc_nodular.png']\n",
    "\n",
    "    if name in imagePath[0]:\n",
    "        image = read_image(imagePath[0], mask = True ) - read_image(imagePath[1], mask = True )\n",
    "        image = (image == 1)*1\n",
    "        mask_img[ image == 1 ]  = 4\n",
    "    return mask_img    \n",
    "\n",
    "\n",
    "\n",
    "def box_image_seg(mask, img, error, Area = 50, more_classes = False):\n",
    "    '''\n",
    "    From an image we can get several images for training\n",
    "    It depends on the minimun area to create a nwe image\n",
    "    It means we have several boxes information which contain localisation information of calcifications  \n",
    "    '''\n",
    "    masks_imgs = []\n",
    "    imgs = []\n",
    "    box_info = []\n",
    "    Area_more_classses = Area*4\n",
    "    n, m = mask.shape\n",
    "\n",
    "\n",
    "    mask_class = np.max(mask)\n",
    "    label = (mask ==mask_class)*1 + (mask == mask_class-1)*1 \n",
    "    label = (label !=0)*1\n",
    "\n",
    "    contours , _ = cv2.findContours(label.astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    idxs =  list(np.where(np.array([cv2.contourArea(x) for x in contours])>Area))[0]\n",
    "    pix  = np.sum(label)\n",
    "    if pix > 12 and len(idxs)>0:   \n",
    "        for idx in idxs:\n",
    "            x,y,w,h = cv2.boundingRect(contours[int(idx)])\n",
    "            box_info.append([x,y,w,h])\n",
    "\n",
    "        \n",
    "    if more_classes:\n",
    "        d = 64\n",
    "        label_more_classses = (mask == mask_class-2)*1  \n",
    "        contours_more_classses , _ = cv2.findContours(label_more_classses.astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        areas = [cv2.contourArea(x) for x in contours_more_classses]\n",
    "        # print(areas)\n",
    "        if areas != []:\n",
    "            idxs_big =  int(list(np.where(areas==np.max(areas)))[0])\n",
    "\n",
    "            x,y,w,h = cv2.boundingRect(contours_more_classses[idxs_big])\n",
    "            img   = label_more_classses[y:y+h,x:x+w]\n",
    "            img_cal = label[y:y+h,x:x+w]\n",
    "\n",
    "            ww, hh = img.shape\n",
    "            if ww >=d and hh >=d:\n",
    "                grid = product(range(0, h-h%d, d), range(0, w-w%d, d))\n",
    "                for i, j in grid:\n",
    "                    if np.sum(img_cal[j:j+d,i:i+d])< d**2//10:\n",
    "                        box_info.append([x+i,y+j,d,d])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    return box_info\n",
    "\n",
    "\n",
    "def read_image_after_before(path , path_after, path_before, mask_Path, error, Area, name, value = None, more_imgs= False):\n",
    "    '''\n",
    "    Create a list of images with a box list (from one image) for  each image at time t, t+1 and t-1\n",
    "    '''\n",
    "    image_list = []\n",
    "    name_list = []\n",
    "    box_list = []\n",
    "    mask_list = []\n",
    "    image = read_image_dicom(path)\n",
    "    image_after = read_image_dicom(path_after)\n",
    "    image_before = read_image_dicom(path_before)\n",
    "    mask =  create_binary_mask(mask_Path, name)\n",
    "    boxes = box_image_seg(mask, image, error, Area, more_imgs)\n",
    "    \n",
    "    for box in boxes:\n",
    "        x,y,w,h =  box\n",
    "        if value:\n",
    "            img = [image[y-error:y+value+error,x-error:x+value+error], image_after[y-error:y+value+error,x-error:x+value+error] , image_before[y-error:y+value+error,x-error:x+value+error]] \n",
    "            mask_list.append(mask[y-error:y+value+error,x-error:x+value+error])\n",
    "        else: \n",
    "            img = [image[y-error:y+h+error,x-error:x+w+error], image_after[y-error:y+h+error,x-error:x+w+error] , image_before[y-error:y+h+error,x-error:x+w+error]] \n",
    "            mask_list.append(mask[y-error:y+h+error,x-error:x+w+error])\n",
    "        image_list.append(img)\n",
    "        name_list.append(name)\n",
    "        box_list.append([x,y,w,h])\n",
    "    return image_list, mask_list, name_list, box_list\n",
    "\n",
    "def create_image_after_before(info_image, info_image_after_before, error, Area, value, more_classes = False):\n",
    "    '''\n",
    "    info_image  dictionary \n",
    "    keys: file name\n",
    "    values: mask, boxes, images (time t)\n",
    "\n",
    "    info_image_after_before dictionary\n",
    "    keys: file names\n",
    "    values: path image at time t, path (t+1), path (t-1)\n",
    "    '''\n",
    "    image_list = []\n",
    "    mask_list = []\n",
    "    name_list = []\n",
    "    box_list = []\n",
    "    \n",
    "    for key in list(info_image_after_before):\n",
    "        #print(key)\n",
    "        mask_Path  = info_image[key]\n",
    "        path , path_after, path_before = info_image_after_before[key]\n",
    "        name = path.split('\\\\')[-1][:-4] \n",
    "        #print(mask_Path[0].split('\\\\')[-1][:-4] ,'\\n', path.split('\\\\')[-1][:-4] , '\\n',path_after.split('\\\\')[-1][:-4], '\\n',path_before.split('\\\\')[-1][:-4],'\\n', key)\n",
    "        imgs, masks_imgs, name_imgs, boxes = read_image_after_before(path , path_after, path_before, mask_Path, error, Area, name, value, more_classes)\n",
    "        box_list += boxes \n",
    "        image_list += imgs\n",
    "        mask_list += masks_imgs\n",
    "        name_list += name_imgs\n",
    "\n",
    "    return image_list, mask_list, name_list, box_list\n",
    "\n",
    "def create_dir_paths(path, train = True):\n",
    "\n",
    "    '''\n",
    "    Function which allows to create paths for training  and test set\n",
    "        4 classes (sheet, nodular, artere and background)\n",
    "    '''\n",
    "    if train:\n",
    "        path_train_masks = os.path.join(path, 'train', 'mask')\n",
    "    else:\n",
    "        path_train_masks = os.path.join(path, 'test', 'mask')\n",
    "\n",
    "    image_Paths  = [os.path.join(path_train_masks, f) for f in os.listdir(path_train_masks) if (f.endswith('grayscale.png') or f.endswith('greyscale.png') ) ]\n",
    "    mask_Paths  = []\n",
    "    #'thrombus',\n",
    "\t# 'lumen',\n",
    "\t# 'formaline',\n",
    "\t# 'soft_tissue',\n",
    "\t# 'fibrous_plaque',\n",
    "\t# 'sheet_calcif',\n",
    "\t# 'nodular_calcif',\n",
    "\t# 'lipid_pool',\n",
    "\t# 'fat_tissue',\n",
    "\t# 'support',\n",
    "\t# 'bck'\n",
    "\n",
    "    classes_imgs = ['_soft_tissue.png','_calc_nodular.png', '_calc_sheet.png']\n",
    "    \n",
    "    # classes_imgs = ['_thrombus.png', '_formaline.png', 'support_.png','_lumen.png','_lipid_pool.png','_fibrous_plaque.png',\\\n",
    "    #     '_fat_tissue.png','_soft_tissue.png','_calc_nodular.png', '_calc_sheet.png']\n",
    "    for file in image_Paths:\n",
    "        mask = []\n",
    "        for classes in classes_imgs:\n",
    "            if os.path.exists(file[:-4]+ classes ):\n",
    "                mask.append(file[:-4]+ classes )\n",
    "            else:\n",
    "                mask.append('')\n",
    "        #print(mask)\n",
    "        mask_Paths.append(mask)\n",
    "\n",
    "    return image_Paths, mask_Paths\n",
    "\n",
    "def norm_image_2d_to_3d(image):\n",
    "    image =  cv2.normalize(image.astype(np.float32),  None, 0, 255, cv2.NORM_MINMAX)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)/255\n",
    "    return image    \n",
    "\n",
    "def data_after_before(image_list_c, mask_list_c):\n",
    "\n",
    "    image_list = [img for img in image_list_c if img[0].shape[0]>0 and  img[0].shape[1]>0]\n",
    "    mask_list = [mask for mask, img in zip(mask_list_c, image_list_c) if img[0].shape[0]>0 and  img[0].shape[1]>0]\n",
    "\n",
    "    image_list_complet = []\n",
    "    for im in image_list:\n",
    "        image_list_complet += im\n",
    "    # print(len(image_list_complet))\n",
    "    # print(image_list_complet[0].shape)\n",
    "    max_v  = np.max([np.max(im) for im in image_list_complet])\n",
    "    min_v  = np.min([np.min(im) for im in image_list_complet])\n",
    "    # print(max_v , min_v)\n",
    "    image_list_complet_norm = [ (im-  min_v)/(max_v -  min_v) for im in image_list_complet]\n",
    "    image_list  = [ [norm_image_2d_to_3d(image_list_complet_norm[3*i]),norm_image_2d_to_3d(image_list_complet_norm[3*i+1]),norm_image_2d_to_3d(image_list_complet_norm[3*i+2])]  for i in np.arange(len(image_list_complet_norm)//3)] \n",
    "    print('Images are created: ', len(image_list))\n",
    "    return image_list, mask_list\n",
    "\n",
    "    # max_vsr  = [np.max([np.max(im[:,:,0]) for im in image_list_complet]), np.max([np.max(im[:,:,1]) for im in image_list_complet]), np.max([np.max(im[:,:,2]) for im in image_list_complet])]\n",
    "    # min_vsr  = [np.min([np.min(im[:,:,0]) for im in image_list_complet]), np.min([np.min(im[:,:,1]) for im in image_list_complet]), np.min([np.min(im[:,:,2]) for im in image_list_complet])]\n",
    "    # print(max_vsr , min_vsr)\n",
    "    # #image_list_completages = [im/ for im in image_list_complet]\n",
    "\n",
    "\n",
    "def create_multi_input_data(error, Area, train_ = True, value = None, more_imgs = False):\n",
    "    '''\n",
    "    Create a multi inpu data set t, t+1, t-1\n",
    "    '''\n",
    "    path_ori = r'C:\\Users\\kmorales\\Desktop\\2DO PhD\\Strasbourg\\Hugo_seg\\originals_180919\\originals'\n",
    "    path = r'C:\\Users\\kmorales\\Desktop\\2DO PhD\\Strasbourg\\Hugo_seg\\ora_180919\\Layers'\n",
    "    path_MCTS = r'C:\\Users\\kmorales\\Desktop\\2DO PhD\\Strasbourg\\MicroCT_data'\n",
    "    path_mcts = [os.path.join(path_MCTS, f) for f in os.listdir(path_MCTS)]\n",
    "    names_files = [f for f in os.listdir(path_MCTS)]#print(path_mcts)\n",
    "\n",
    "    # 1. Names of availables images (mask +images) at time t\n",
    "    image_Paths, mask_Paths = create_dir_paths(path, train=train_)\n",
    "    info_image_dic = [[j.split('\\\\')[-1].split('.')[0].replace('-A', '').replace('_A', ''), i] for i,j in zip(mask_Paths, image_Paths)]\n",
    "    info_image = {info_image_dic[i][0]: info_image_dic[i][1] for i in range(len(info_image_dic))}\n",
    "    names = list(info_image.keys())\n",
    "    names_after = [file[:-4]+str_after_before(int(file[-4:]) + 1) for file in names]\n",
    "    names_before = [file[:-4]+str_after_before(int(file[-4:]) - 1) for file in names]\n",
    "    # 2. Creation of paths t, t-1, t+1\n",
    "    image_Paths_actual = create_path_after_before(path_mcts , names, names_files)\n",
    "    image_Paths_after = create_path_after_before(path_mcts , names_after, names_files)\n",
    "    image_Paths_before = create_path_after_before(path_mcts , names_before, names_files)\n",
    "    # 3. Saving the information using a dictionary \n",
    "    #print(len(image_Paths_actual), len(image_Paths_after), len(image_Paths_before))\n",
    "    names_after_before = [path.split('\\\\')[-1][:-4] for path in image_Paths_actual]\n",
    "    info_image_after_before = {names_after_before[i]: [image_Paths_actual[i], image_Paths_after[i], image_Paths_before[i] ]for i in range(len(names_after_before))}\n",
    "    # 4. Lists which contain microCT at time t, t+1, t-1 and the mask asociated \n",
    "    image_list, mask_list, names_list, boxes = create_image_after_before(info_image, info_image_after_before, error, Area, value, more_imgs)\n",
    "    # print('number of images:', len(image_Paths), len(mask_Paths))\n",
    "    # print('nombres disponibles: ', len(names))\n",
    "    return image_list, mask_list, names_list, boxes\n",
    "\n",
    "def value_boxes(boxes, value, porcentage = 0.80):\n",
    "    '''This function allows to analyse which value can we use for all images in order \n",
    "    to avoid re-scale the images for training\n",
    "    '''\n",
    "    n = [box[-1] for box in boxes]#h\n",
    "    m = [box[-2] for box in boxes]#w\n",
    "    x  = np.sum([1 for i in n if i< value])/len(n)\n",
    "    y = np.sum([1 for i in n if i< value])/len(m)\n",
    "\n",
    "    if x>=porcentage and y>=porcentage:\n",
    "        print('This value is correct')\n",
    "        print(y)\n",
    "        print(x)\n",
    "    else:\n",
    "        print('Change the value')\n",
    "        print(y)\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import torch \n",
    "class Segmentation_after_before(Dataset):\n",
    "    def __init__(self, imageList, maskList, image_shape, transforms = None, error = 20):\n",
    "        # store the image and mask filepaths, and augmentation\n",
    "        # transforms\n",
    "        self.imageList = imageList\n",
    "        self.maskList = maskList\n",
    "        self.transforms = transforms\n",
    "        self.error  =  error\n",
    "        self.image_shape =  image_shape\n",
    "        #self.training = training\n",
    "    def __len__(self):\n",
    "        return len(self.imageList)\n",
    "\n",
    "    def _get_tensor_image_(self, image):\n",
    "        image = cv2.resize(image, self.image_shape, interpolation=cv2.INTER_NEAREST)\n",
    "        image = torch.tensor(image, dtype=torch.float32).permute(2,0,1)\n",
    "        if self.transforms is not None:\n",
    "            transformed = self.transforms(image=image)\n",
    "            image = transformed[\"image\"]\n",
    "        return image\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # grab the image path from the current index\n",
    "        # t, t+1, t-1 \n",
    "        image_t  = self._get_tensor_image_(self.imageList[idx][0])\n",
    "        image_after  = self._get_tensor_image_(self.imageList[idx][1])\n",
    "        image_before  = self._get_tensor_image_(self.imageList[idx][2])\n",
    "        \n",
    "        mask = self.maskList[idx]\n",
    "        mask = cv2.resize(mask, self.image_shape, interpolation=cv2.INTER_NEAREST)\n",
    "        mask = torch.tensor(mask, dtype=torch.long) \n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            transformed = self.transforms(mask=mask)\n",
    "            mask = transformed[\"mask\"]\n",
    "        \n",
    "        return image_t, image_after, image_before, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def training_Unet(dataloaders, epochs, device, loss_fn, net, optimizer, modelPath, multi = False):\n",
    "    train_loss = [] \n",
    "    for epoch in range(epochs):\n",
    "        for step, batch in enumerate(dataloaders): \n",
    "            if multi:\n",
    "                X, X_af, X_be, y = batch\n",
    "                X, X_af, X_be, y = X.to(device), X_af.to(device), X_be.to(device), y.to(device)\n",
    "                outputs = net(X, X_af, X_be)\n",
    "            else:\n",
    "                X, y = batch\n",
    "                X, y  = X.to(device), y.to(device)\n",
    "                outputs = net(X)\n",
    "\n",
    "            loss = loss_fn(outputs, y)\n",
    "\n",
    "            if step % 30 == 0:\n",
    "                    # clear_output(wait=True)\n",
    "                    print('Current step: {}  Loss: {}  '.format(step, loss))\n",
    "                    \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_loss = loss / len(dataloaders.dataset)\n",
    "        train_loss.append(epoch_loss)\n",
    "        if epoch % 5 == 0: #Save model weight once every 60k steps permenant file\n",
    "                print(\"Saving Model\" +str(epoch) + \".torch\")\n",
    "                torch.save(net.state_dict(),   os.path.join(modelPath,str(epoch) + \".torch\") )\n",
    "    \n",
    "    train_loss_ = [train_loss[i].item() for i in range(len(train_loss))]\n",
    "    plt.plot(train_loss_)\n",
    "    plt.show()\n",
    "    np.save(os.path.join(modelPath,'loss'+str(epoch) + \".npy\"), train_loss_)\n",
    "    return train_loss, train_loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "class UNET_multi(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = self.contract_block(in_channels, 32, 7, 3)\n",
    "        self.conv2 = self.contract_block(32, 64, 3, 1)\n",
    "        self.conv3 = self.contract_block(64, 128, 3, 1)\n",
    "\n",
    "        self.upconv3 = self.expand_block(128, 64, 3, 1)\n",
    "        self.upconv2 = self.expand_block(64*2, 32, 3, 1)\n",
    "        self.upconv1 = self.expand_block(32*2, out_channels, 3, 1)\n",
    "\n",
    "    def forward(self, t, af, be):\n",
    "        x = torch.cat((be, t, af), 1) \n",
    "        # downsampling part\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv3 = self.conv3(conv2)\n",
    "\n",
    "        upconv3 = self.upconv3(conv3)\n",
    "        upconv2 = self.upconv2(torch.cat([upconv3, conv2], 1))\n",
    "        upconv1 = self.upconv1(torch.cat([upconv2, conv1], 1))\n",
    "\n",
    "        return upconv1\n",
    "\n",
    "    def contract_block(self, in_channels, out_channels, kernel_size, padding):\n",
    "\n",
    "        contract = nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "                                 )\n",
    "\n",
    "        return contract\n",
    "\n",
    "    def expand_block(self, in_channels, out_channels, kernel_size, padding):\n",
    "\n",
    "        expand = nn.Sequential(torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=padding),\n",
    "                            torch.nn.BatchNorm2d(out_channels),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=padding),\n",
    "                            torch.nn.BatchNorm2d(out_channels),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1) \n",
    "                            )\n",
    "        return expand\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, logits, true, eps=1e-7, Test = False):\n",
    "        num_classes = logits.shape[1]\n",
    "        if num_classes == 1:\n",
    "            true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n",
    "            true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "            true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
    "            true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
    "            true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
    "            pos_prob = torch.sigmoid(logits)\n",
    "            neg_prob = 1 - pos_prob\n",
    "            probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
    "        else:\n",
    "            true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n",
    "            true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "            probas = F.softmax(logits, dim=1)\n",
    "        true_1_hot = true_1_hot.type(logits.type())\n",
    "        dims = (0,) + tuple(range(2, true.ndimension()))\n",
    "        intersection = torch.sum(probas * true_1_hot, dims)\n",
    "        cardinality = torch.sum(probas + true_1_hot, dims)\n",
    "        dice_loss_classes = (2. * intersection / (cardinality + eps))\n",
    "        dice_loss = dice_loss_classes.mean()\n",
    "        \n",
    "        if Test:   \n",
    "            return  dice_loss_classes.mean(1).detach().numpy(),  (1 - dice_loss)\n",
    "        else:\n",
    "            return (1 - dice_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNET WIT DIFFERENT CLASSES\n",
    "\n",
    "- 2 CALCIFICATIONS\n",
    "- NO CALCIFICATIONS AT ALL \n",
    "- BACKGROUND\n",
    "\n",
    "## IMAGES GENERATION:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------\n",
    "# 0. Data parameters to create the dataset \n",
    "error = 0\n",
    "Area = 50\n",
    "train =  True\n",
    "# With only the criteria of 2 calcifications: 223 Images and masks are created\n",
    "more_classes =  False\n",
    "\n",
    "image_list, mask_list, name_list, boxes = create_multi_input_data(error, Area, train_ = train, more_imgs=more_classes)\n",
    "print('Images and masks are created:', len(image_list))\n",
    "# with multi 3 with only 3 classes\n",
    "# Images and masks are created\n",
    "# 166 166"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_list[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = 100\n",
    "op_value = value_boxes(boxes, value, porcentage = 0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------\n",
    "# 0. Data parameters to create the dataset \n",
    "# with multi 3 with only 3 classes 166 images\n",
    "# With only the criteria of 2 calcifications: 223 Images and masks are created\n",
    "more_classes =  True\n",
    "image_list, mask_list, name_list, boxes = create_multi_input_data(error, Area, train_ = train, more_imgs=more_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 20\n",
    "image = image_list[index][0]\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #calc = [f for f in os.listdir(r'C:\\Users\\kmorales\\Desktop\\2DO PhD\\Strasbourg\\Hugo_seg\\ora_180919\\Layers\\test\\mask') if 'calc' in f ]\n",
    "# calc = [f for f in os.listdir(r'C:\\Users\\kmorales\\Desktop\\2DO PhD\\Strasbourg\\Hugo_seg\\ora_180919\\Layers\\test\\mask') if 'calc' in f and 'png' in f ]\n",
    "\n",
    "# calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------\n",
    "# 0. Data parameters to create the dataset \n",
    "op_value = None\n",
    "error = 15\n",
    "Area = 50\n",
    "train =  True\n",
    "more_classes =  True\n",
    "image_list, mask_list, name_list, boxes = create_multi_input_data(error, Area, train_ = train, more_imgs=more_classes, value= op_value)\n",
    "print('Images and masks are created:', len(image_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_imgs = [img for img in image_list if img.shape[0]>0 and  img.shape[1]>0:]\n",
    "final_masks = [mask for mask, img in zip(mask_list, image_list) if img.shape[0]>0 and  img.shape[1]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = []\n",
    "m = []\n",
    "list_labels = []\n",
    "all_labels = []\n",
    "\n",
    "for i in range(len(mask_list)):\n",
    "    labels, counts_elements = np.unique(mask_list[i], return_counts=True)\n",
    "    all_labels = all_labels + list(labels)\n",
    "    #print(name_list[i], labels, [np.round(x*100) for x in counts_elements/np.sum(counts_elements)], mask_list[i].shape)\n",
    "    n.append(mask_list[i].shape[0])\n",
    "    m.append(mask_list[i].shape[1])\n",
    "    # if 4 not in labels and 3 not in labels:\n",
    "    #     print(name_list[i], labels, mask_list[i].shape)\n",
    "\n",
    "labels, counts_elements = np.unique(all_labels, return_counts=True)\n",
    "print(labels, '\\n',[np.round(x*100) for x in counts_elements/np.sum(counts_elements)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualization of random images \n",
    "def plot_images(seg_resize, srCT_resize , datos):\n",
    "    fig = plt.figure(figsize=(15,400 ))\n",
    "    j = len(seg_resize)//2\n",
    "    k = 0\n",
    "    h = 0\n",
    "    for i in range(k,k+j):\n",
    "        ax  =  plt.subplot(j, 4, 4*h+1)\n",
    "        ax.imshow(seg_resize[2*i])\n",
    "        ax.set_title(\"SEG CT  \"+str(datos[2*i]))\n",
    "        \n",
    "        ax  =  plt.subplot(j, 4, 4*h+2)\n",
    "        ax.imshow(srCT_resize[2*i][0])\n",
    "        ax.set_title(\"CT  \"+str(datos[2*i]))\n",
    "        \n",
    "        ax  =  plt.subplot(j, 4, 4*h+3)\n",
    "        ax.imshow(seg_resize[2*i+1])\n",
    "        ax.set_title(\"SEG CT  \"+str(datos[2*i+1]))\n",
    "        \n",
    "        ax  =  plt.subplot(j, 4, 4*h+4)\n",
    "        ax.imshow(srCT_resize[2*i+1][0])\n",
    "        ax.set_title(\"CT  \"+str(datos[2*i+1]))   \n",
    "        h +=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(mask_list[:100], image_list[:100] , name_list[:100])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#i = np.random.randint(0, len(mask_list))\n",
    "i = 51\n",
    "print(np.unique(image_list[i][0]))\n",
    "print(name_list[i], np.unique(mask_list[i]), name_list[i+1],np.unique(mask_list[i+1]) )\n",
    "plt.imshow(mask_list[i])\n",
    "plt.show()\n",
    "plt.imshow(image_list[i][0])\n",
    "plt.show()\n",
    "plt.imshow(mask_list[i+1])\n",
    "plt.show()\n",
    "plt.imshow(image_list[i+1][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model 1 more_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_value = None\n",
    "error = 15\n",
    "Area = 50\n",
    "train =  True\n",
    "more_classes =  True\n",
    "image_list, mask_list, name_list, boxes = create_multi_input_data(error, Area, train_ = train, more_imgs=more_classes, value= op_value)\n",
    "print('Images and masks are created:', len(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD images from SR data saet SFA006\n",
    "SR_img_list = (np.load(r'C:\\Users\\kmorales\\Desktop\\2DO PhD\\Strasbourg\\Hugo_seg\\ora_180919\\Layers\\train\\SR_SFA006_images.npy'))\n",
    "SR_img_list = SR_img_list.tolist()\n",
    "n,m = 64, 64\n",
    "SR_mask_list = [np.zeros((n,m),np.int64) ]*len(SR_img_list)\n",
    "print('len SR mask', len(SR_mask_list ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SR_list_data(SR_image):\n",
    "    img =  cv2.normalize(SR_image.astype(np.float32),  None, 0, 255, cv2.NORM_MINMAX)         \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img\n",
    "\n",
    "SR_img_list_aux  = (np.load(r'C:\\Users\\kmorales\\Desktop\\2DO PhD\\Strasbourg\\Hugo_seg\\ora_180919\\Layers\\train\\SR_SFA006_images.npy'))\n",
    "SR_img_list= [[SR_list_data(SR_img_list_aux[i][0]), SR_list_data(SR_img_list_aux[i][1]) , \\\n",
    "    SR_list_data(SR_img_list_aux[i][2])] for i in range(SR_img_list_aux.shape[0])]\n",
    "# SR_img_list= [[cv2.cvtColor(SR_img_list_aux[i][0], cv2.COLOR_BGR2GRAY), cv2.cvtColor(SR_img_list_aux[i][1], cv2.COLOR_BGR2GRAY) , cv2.cvtColor(SR_img_list_aux[i][2], cv2.COLOR_BGR2GRAY)] for i in range(SR_img_list_aux.shape[0])]\n",
    "\n",
    "#print(SR_img_list.shape)\n",
    "print(image_list.__class__)\n",
    "print(image_list[0].__class__)\n",
    "print(SR_img_list.__class__)\n",
    "print(SR_img_list[0].__class__)\n",
    "#print(SR_img_list[0].shape)\n",
    "print(SR_img_list[0][0].__class__)\n",
    "print(image_list[0][0].__class__)\n",
    "print(SR_img_list[0][0].shape)\n",
    "print(image_list[0][0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SR_img_list[0][0].shape)\n",
    "print(image_list[0][0].shape)\n",
    "def SR_list_data(SR_image):\n",
    "    img =  cv2.normalize(SR_image.astype(np.float32),  None, 0, 255, cv2.NORM_MINMAX)         \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img\n",
    "\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "# plt.imshow(image_list[0][0])\n",
    "# print(img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = image_list + SR_img_list\n",
    "mask_list = mask_list + SR_mask_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_list)\n",
    "#image_list[0][0].__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list, mask_list =  data_after_before(image_list, mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (64, 64) \n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "data = Segmentation_after_before(image_list, mask_list, image_shape)\n",
    "dataloaders = torch.utils.data.DataLoader(data, batch_size)\n",
    "#----------------------\n",
    "# Model \n",
    "input_channels = 9\n",
    "num_classes = 5\n",
    "learning_rate = 1e-3  \n",
    "epochs = 101\n",
    "loss_fn  =  DiceLoss() \n",
    "folder_name = 'model_unet_multi_2_more_classes'\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelPath = os.path.join(r'C:\\Users\\kmorales\\Desktop\\2DO PhD\\Strasbourg\\Hugo_seg', folder_name)\n",
    "if not os.path.exists(modelPath):\n",
    "    os.makedirs(modelPath)\n",
    "\n",
    "net = UNET_multi(input_channels, num_classes) \n",
    "net.to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0)\n",
    "#summary(net)\n",
    "#sum(p.numel() for p in net.parameters() if p.requires_grad) \n",
    "tloss, tloss_list = training_Unet(dataloaders, epochs, device, loss_fn, net, optimizer, modelPath,  multi= True)\n",
    "plt.plot(tloss_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with images SR from center line SFA006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def test_multi(net, loss_fn, dataloaders_test, device,num_classes, plot_ = True, multi = False):\n",
    "    loss_classes =  np.array([[0] * num_classes])\n",
    "    loss = []\n",
    "    for _, batch in enumerate(dataloaders_test): \n",
    "        if multi:\n",
    "                X, X_af, X_be, y = batch\n",
    "                X, X_af, X_be, y = X.to(device), X_af.to(device), X_be.to(device), y.to(device)\n",
    "                pred = net(X, X_af, X_be)\n",
    "        else:\n",
    "                X, y = batch\n",
    "                X, y  = X.to(device), y.to(device)\n",
    "                pred = net(X)\n",
    "\n",
    "        seg = torch.argmax(pred, dim=1).detach().numpy()[0]# torch.argmax(pred, 1).numpy()  # Get  prediction classes\n",
    "        loss_v = loss_fn(pred, y)\n",
    "        loss_classes_  = []\n",
    "        for i in range(pred.shape[1]):\n",
    "            y1 = 1*(y==i)\n",
    "            pred1 = pred[:,i,:,:].unsqueeze(0)\n",
    "            loss_classes_.append(-(loss_fn(pred1, y1).item()-1))\n",
    "        #loss_classes_ , loss_v = loss_fn(pred, y, Test = True)\n",
    "        loss_classes  = np.concatenate((loss_classes, np.array([loss_classes_])), axis = 0)\n",
    "        loss.append(loss_v.item())\n",
    "        print(loss_v)\n",
    "        # print(seg.shape)\n",
    "        # print(y.squeeze().detach().numpy().shape)\n",
    "\n",
    "        print(metrics.classification_report(y.squeeze().detach().numpy().flatten(), seg.flatten(), digits=5))\n",
    "\n",
    "        if plot_:\n",
    "            print(loss_classes_)\n",
    "            _, (ax1, ax2, ax3) = plt.subplots(1,3)\n",
    "            ax1.imshow(X.squeeze().permute(1,2,0))\n",
    "            ax2.imshow(seg)\n",
    "            ax3.imshow(y.squeeze())\n",
    "            plt.show()\n",
    "    return loss_classes[1:,:].mean(0), np.mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Constants\n",
    "# C=\"Cat\"\n",
    "# F=\"Fish\"\n",
    "# H=\"Hen\"\n",
    "\n",
    "# # True values\n",
    "# y_true = [C,C,C,C,C,C, F,F,F,F,F,F,F,F,F,F, H,H,H,H,H,H,H,H,H]\n",
    "# # Predicted values\n",
    "# y_pred = [C,C,C,C,H,F, C,C,C,C,C,C,H,H,F,F, C,C,C,H,H,H,H,H,H]\n",
    "\n",
    "# # Print the confusion matrix\n",
    "# print(metrics.confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# # Print the precision and recall, among other metrics\n",
    "# report = metrics.classification_report(y_true, y_pred, digits=3, output_dict=True)\n",
    "# macro_precision =  report['macro avg']['precision'] \n",
    "# macro_recall = report['macro avg']['recall']    \n",
    "# macro_f1 = report['macro avg']['f1-score']\n",
    "# report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "# y_true = [0, 1, 2, 2, 2]\n",
    "# y_pred = [0, 0, 2, 2, 1]\n",
    "# target_names = ['class 0', 'class 1', 'class 2']\n",
    "\n",
    "# print(f1_score(y_true, y_pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------\n",
    "# TEST:\n",
    "#---------------------\n",
    "#  Data parameters to create the dataset \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "op_value = None\n",
    "error = 20\n",
    "Area = 100\n",
    "train =  False\n",
    "more_classes =  True\n",
    "image_list, mask_list, name_list, boxes = create_multi_input_data(error, Area, train_ = train, more_imgs=more_classes, value= op_value)\n",
    "print('Images and masks are created:', len(image_list))\n",
    "image_list, mask_list =  data_after_before(image_list, mask_list)\n",
    "\n",
    "\n",
    "\n",
    "image_shape = (128,128) \n",
    "batch_size = 1\n",
    "data = Segmentation_after_before(image_list, mask_list, image_shape)\n",
    "dataloaders_test = torch.utils.data.DataLoader(data, batch_size)\n",
    "\n",
    "#----------------------\n",
    "# Model  Parameters\n",
    "input_channels = 9\n",
    "num_classes = 5\n",
    "\n",
    "loss_fn  =  DiceLoss() \n",
    "folder_name = 'model_unet_multi_2_more_classes'\n",
    "epoch_init = '100.torch'\n",
    "\n",
    "#----------------------\n",
    "# Model initialization\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelPath = os.path.join(r'C:\\Users\\kmorales\\Desktop\\2DO PhD\\Strasbourg\\Hugo_seg', folder_name)\n",
    "net = UNET_multi(input_channels, num_classes) \n",
    "net.to(device)\n",
    "net.load_state_dict(torch.load(os.path.join(modelPath , epoch_init))) # Load trained model\n",
    "net.eval()\n",
    "#######################################\n",
    "# UNET Model 1  Multi Input More classes\n",
    "loss_fn  =  DiceLoss()  \n",
    "dice_score_classes, loss = test_multi(net, loss_fn, dataloaders_test, device,num_classes, plot_ = True, multi = True )\n",
    "print(dice_score_classes, loss)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNET 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------\n",
    "op_value = None\n",
    "error = 15\n",
    "Area = 50\n",
    "train =  True\n",
    "more_classes =  True\n",
    "image_list, mask_list, name_list, boxes = create_multi_input_data(error, Area, train_ = train, more_imgs=more_classes, value= op_value)\n",
    "print('Images and masks are created:', len(image_list))\n",
    "image_list, mask_list =  data_after_before(image_list, mask_list)\n",
    "\n",
    "\n",
    "image_shape = (64, 64) \n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "data = Segmentation_after_before(image_list, mask_list, image_shape)\n",
    "dataloaders = torch.utils.data.DataLoader(data, batch_size)\n",
    "#----------------------\n",
    "# Model \n",
    "input_channels = 9\n",
    "num_classes = 5\n",
    "learning_rate = 1e-3  \n",
    "epochs = 101\n",
    "loss_fn  =  DiceLoss() \n",
    "folder_name = 'model_unet_multi_1_more_classes'\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelPath = os.path.join(r'C:\\Users\\kmorales\\Desktop\\2DO PhD\\Strasbourg\\Hugo_seg', folder_name)\n",
    "if not os.path.exists(modelPath):\n",
    "    os.makedirs(modelPath)\n",
    "\n",
    "net = UNET_multi(input_channels, num_classes) \n",
    "net.to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0)\n",
    "#summary(net)\n",
    "#sum(p.numel() for p in net.parameters() if p.requires_grad) \n",
    "tloss, tloss_list = training_Unet(dataloaders, epochs, device, loss_fn, net, optimizer, modelPath,  multi= True)\n",
    "plt.plot(tloss_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------\n",
    "op_value = None\n",
    "error = 15\n",
    "Area = 100\n",
    "train =  True\n",
    "more_classes =  True\n",
    "image_list, mask_list, name_list, boxes = create_multi_input_data(error, Area, train_ = train, more_imgs=more_classes, value= op_value)\n",
    "print('Images and masks are created:', len(image_list))\n",
    "image_list, mask_list =  data_after_before(image_list, mask_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------\n",
    "op_value = None\n",
    "error = 20\n",
    "Area = 100\n",
    "train =  True\n",
    "more_classes =  True\n",
    "image_list, mask_list, name_list, boxes = create_multi_input_data(error, Area, train_ = train, more_imgs=more_classes, value= op_value)\n",
    "print('Images and masks are created:', len(image_list))\n",
    "image_list, mask_list =  data_after_before(image_list, mask_list)\n",
    "\n",
    "\n",
    "image_shape = (128, 128) \n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "data = Segmentation_after_before(image_list, mask_list, image_shape)\n",
    "dataloaders = torch.utils.data.DataLoader(data, batch_size)\n",
    "#----------------------\n",
    "# Model \n",
    "input_channels = 9\n",
    "num_classes = 5\n",
    "learning_rate = 5e-3  \n",
    "epochs = 201\n",
    "loss_fn  =  DiceLoss() \n",
    "folder_name = 'model_unet_multi_2_more_classes'\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelPath = os.path.join(r'C:\\Users\\kmorales\\Desktop\\2DO PhD\\Strasbourg\\Hugo_seg', folder_name)\n",
    "if not os.path.exists(modelPath):\n",
    "    os.makedirs(modelPath)\n",
    "\n",
    "net = UNET_multi(input_channels, num_classes) \n",
    "net.to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0)\n",
    "#summary(net)\n",
    "#sum(p.numel() for p in net.parameters() if p.requires_grad) \n",
    "tloss, tloss_list = training_Unet(dataloaders, epochs, device, loss_fn, net, optimizer, modelPath,  multi= True)\n",
    "plt.plot(tloss_list)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multi(net, loss_fn, dataloaders_test, device,num_classes, plot_ = True, multi = False):\n",
    "    loss_classes =  np.array([[0] * num_classes])\n",
    "    loss = []\n",
    "    for _, batch in enumerate(dataloaders_test): \n",
    "        if multi:\n",
    "                X, X_af, X_be, y = batch\n",
    "                X, X_af, X_be, y = X.to(device), X_af.to(device), X_be.to(device), y.to(device)\n",
    "                pred = net(X, X_af, X_be)\n",
    "        else:\n",
    "                X, y = batch\n",
    "                X, y  = X.to(device), y.to(device)\n",
    "                pred = net(X)\n",
    "\n",
    "        seg = torch.argmax(pred, dim=1).numpy()[0]# torch.argmax(pred, 1).numpy()  # Get  prediction classes\n",
    "        loss_v = loss_fn(pred, y)\n",
    "        loss_classes_  = []\n",
    "        for i in range(pred.shape[1]):\n",
    "            y1 = 1*(y==i)\n",
    "            pred1 = pred[:,i,:,:].unsqueeze(0)\n",
    "            loss_classes_.append(-(loss_fn(pred1, y1).item()-1))\n",
    "        #loss_classes_ , loss_v = loss_fn(pred, y, Test = True)\n",
    "        loss_classes  = np.concatenate((loss_classes, np.array([loss_classes_])), axis = 0)\n",
    "        loss.append(loss_v.item())\n",
    "        print(loss_v)\n",
    "        if plot_:\n",
    "            print(loss_classes_)\n",
    "            _, (ax1, ax2, ax3) = plt.subplots(1,3)\n",
    "            ax1.imshow(X.squeeze().permute(1,2,0))\n",
    "            ax2.imshow(seg)\n",
    "            ax3.imshow(y.squeeze())\n",
    "            plt.show()\n",
    "    return loss_classes[1:,:].mean(0), np.mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------\n",
    "# 0. Data parameters to create the dataset \n",
    "\n",
    "\n",
    "op_value = None\n",
    "error = 20\n",
    "Area = 100\n",
    "train =  False\n",
    "more_classes =  True\n",
    "image_list, mask_list, name_list, boxes = create_multi_input_data(error, Area, train_ = train, more_imgs=more_classes, value= op_value)\n",
    "print('Images and masks are created:', len(image_list))\n",
    "image_list, mask_list =  data_after_before(image_list, mask_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------\n",
    "# 0. Data parameters to create the dataset \n",
    "\n",
    "\n",
    "op_value = None\n",
    "error = 20\n",
    "Area = 100\n",
    "train =  False\n",
    "more_classes =  False\n",
    "image_list, mask_list, name_list, boxes = create_multi_input_data(error, Area, train_ = train, more_imgs=more_classes, value= op_value)\n",
    "print('Images and masks are created:', len(image_list))\n",
    "image_list, mask_list =  data_after_before(image_list, mask_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------\n",
    "# TEST:\n",
    "#---------------------\n",
    "#  Data parameters to create the dataset \n",
    "\n",
    "op_value = None\n",
    "error = 20\n",
    "Area = 100\n",
    "train =  False\n",
    "more_classes =  True\n",
    "image_list, mask_list, name_list, boxes = create_multi_input_data(error, Area, train_ = train, more_imgs=more_classes, value= op_value)\n",
    "print('Images and masks are created:', len(image_list))\n",
    "image_list, mask_list =  data_after_before(image_list, mask_list)\n",
    "\n",
    "\n",
    "\n",
    "image_shape = (128,128) \n",
    "batch_size = 1\n",
    "data = Segmentation_after_before(image_list, mask_list, image_shape)\n",
    "dataloaders_test = torch.utils.data.DataLoader(data, batch_size)\n",
    "\n",
    "#----------------------\n",
    "# Model  Parameters\n",
    "input_channels = 9\n",
    "num_classes = 5\n",
    "\n",
    "loss_fn  =  DiceLoss() \n",
    "folder_name = 'model_unet_multi_1_more_classes'\n",
    "epoch_init = '100.torch'\n",
    "\n",
    "#----------------------\n",
    "# Model initialization\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelPath = os.path.join(r'C:\\Users\\kmorales\\Desktop\\2DO PhD\\Strasbourg\\Hugo_seg', folder_name)\n",
    "net = UNET_multi(input_channels, num_classes) \n",
    "net.to(device)\n",
    "net.load_state_dict(torch.load(os.path.join(modelPath , epoch_init))) # Load trained model\n",
    "net.eval()\n",
    "#######################################\n",
    "# UNET Model 1  Multi Input More classes\n",
    "loss_fn  =  DiceLoss()  \n",
    "dice_score_classes, loss = test_multi(net, loss_fn, dataloaders_test, device,num_classes, plot_ = True, multi = True )\n",
    "print(dice_score_classes, loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------\n",
    "# TEST:\n",
    "#---------------------\n",
    "#  Data parameters to create the dataset \n",
    "\n",
    "op_value = None\n",
    "error = 20\n",
    "Area = 100\n",
    "train =  False\n",
    "more_classes =  True\n",
    "image_list, mask_list, name_list, boxes = create_multi_input_data(error, Area, train_ = train, more_imgs=more_classes, value= op_value)\n",
    "print('Images and masks are created:', len(image_list))\n",
    "image_list, mask_list =  data_after_before(image_list, mask_list)\n",
    "\n",
    "\n",
    "\n",
    "image_shape = (128,128) \n",
    "batch_size = 1\n",
    "data = Segmentation_after_before(image_list, mask_list, image_shape)\n",
    "dataloaders_test = torch.utils.data.DataLoader(data, batch_size)\n",
    "\n",
    "#----------------------\n",
    "# Model  Parameters\n",
    "input_channels = 9\n",
    "num_classes = 5\n",
    "\n",
    "loss_fn  =  DiceLoss() \n",
    "folder_name = 'model_unet_multi_1_more_classes'\n",
    "epoch_init = '100.torch'\n",
    "\n",
    "#----------------------\n",
    "# Model initialization\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelPath = os.path.join(r'C:\\Users\\kmorales\\Desktop\\2DO PhD\\Strasbourg\\Hugo_seg', folder_name)\n",
    "net = UNET_multi(input_channels, num_classes) \n",
    "net.to(device)\n",
    "net.load_state_dict(torch.load(os.path.join(modelPath , epoch_init))) # Load trained model\n",
    "net.eval()\n",
    "#######################################\n",
    "# UNET Model 1  Multi Input More classes\n",
    "loss_fn  =  DiceLoss()  \n",
    "dice_score_classes, loss = test_multi(net, loss_fn, dataloaders_test, device,num_classes, plot_ = True, multi = True )\n",
    "print(dice_score_classes, loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------\n",
    "# TEST:\n",
    "#---------------------\n",
    "#  Data parameters to create the dataset \n",
    "\n",
    "op_value = None\n",
    "error = 20\n",
    "Area = 100\n",
    "train =  False\n",
    "more_classes =  True\n",
    "image_list, mask_list, name_list, boxes = create_multi_input_data(error, Area, train_ = train, more_imgs=more_classes, value= op_value)\n",
    "print('Images and masks are created:', len(image_list))\n",
    "image_list, mask_list =  data_after_before(image_list, mask_list)\n",
    "\n",
    "\n",
    "\n",
    "image_shape = (64,64) \n",
    "batch_size = 1\n",
    "data = Segmentation_after_before(image_list, mask_list, image_shape)\n",
    "dataloaders_test = torch.utils.data.DataLoader(data, batch_size)\n",
    "\n",
    "#----------------------\n",
    "# Model  Parameters\n",
    "input_channels = 9\n",
    "num_classes = 5\n",
    "\n",
    "loss_fn  =  DiceLoss() \n",
    "folder_name = 'model_unet_multi_2_more_classes'\n",
    "epoch_init = '100.torch'\n",
    "\n",
    "#----------------------\n",
    "# Model initialization\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelPath = os.path.join(r'C:\\Users\\kmorales\\Desktop\\2DO PhD\\Strasbourg\\Hugo_seg', folder_name)\n",
    "net = UNET_multi(input_channels, num_classes) \n",
    "net.to(device)\n",
    "net.load_state_dict(torch.load(os.path.join(modelPath , epoch_init))) # Load trained model\n",
    "net.eval()\n",
    "#######################################\n",
    "# UNET Model 2  Multi Input More classes\n",
    "loss_fn  =  DiceLoss()  \n",
    "dice_score_classes, loss = test_multi(net, loss_fn, dataloaders_test, device,num_classes, plot_ = True, multi = True )\n",
    "print(dice_score_classes, loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad1b2571548246114fecf39d36c90373949ef600ffd6c7010bad9bfc5901cee0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
